#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå¼€å§‹ç¤ºä¾‹ - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æå–çš„VAEæƒé‡
è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
"""

import torch
import os


def quick_demo():
    """
    å¿«é€Ÿæ¼”ç¤ºå¦‚ä½•åŠ è½½å’Œä½¿ç”¨VAE
    """
    print("=" * 80)
    print("ğŸš€ Direct3D-S2 VAEå¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("=" * 80)
    
    # æ£€æŸ¥VAEæƒé‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    vae_dir = "./vae_weights"
    dense_vae_path = os.path.join(vae_dir, "dense_vae.pth")
    
    if not os.path.exists(dense_vae_path):
        print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ°VAEæƒé‡æ–‡ä»¶!")
        print("\nè¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤æå–VAEæƒé‡:")
        print("  python extract_vae_weights.py")
        print("\næˆ–è€…ä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„:")
        print("  python extract_vae_weights.py --output-dir ./vae_weights")
        return
    
    print("\nâœ… æ‰¾åˆ°VAEæƒé‡æ–‡ä»¶")
    
    # ==================== ç¤ºä¾‹1: æŸ¥çœ‹VAEä¿¡æ¯ ====================
    print("\n" + "=" * 80)
    print("ğŸ“‹ ç¤ºä¾‹1: æŸ¥çœ‹VAEåŸºæœ¬ä¿¡æ¯")
    print("=" * 80)
    
    saved_data = torch.load(dense_vae_path, map_location='cpu')
    vae_state_dict = saved_data['vae']
    vae_config = saved_data.get('config', None)
    
    print(f"\nğŸ“¦ Dense VAEä¿¡æ¯:")
    print(f"  - æƒé‡é”®æ•°é‡: {len(vae_state_dict)}")
    print(f"  - æ€»å‚æ•°é‡: {sum(p.numel() for p in vae_state_dict.values()):,}")
    
    if vae_config:
        print(f"\nâš™ï¸  é…ç½®å‚æ•°:")
        params = vae_config.get('params', vae_config)
        for key, value in list(params.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"    - {key}: {value}")
        print(f"    ... (å…±{len(params)}ä¸ªå‚æ•°)")
    
    # ==================== ç¤ºä¾‹2: åŠ è½½VAEæ¨¡å‹ ====================
    print("\n" + "=" * 80)
    print("ğŸ”§ ç¤ºä¾‹2: åŠ è½½VAEæ¨¡å‹")
    print("=" * 80)
    
    try:
        from direct3d_s2.models.autoencoders.dense_vae import DenseShapeVAE
        
        # åˆ›å»ºæ¨¡å‹
        if vae_config:
            params = vae_config.get('params', vae_config)
            vae = DenseShapeVAE(**params)
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            vae = DenseShapeVAE(
                embed_dim=8,
                model_channels_encoder=[32, 128, 512],
                model_channels_decoder=[512, 128, 32],
            )
        
        # åŠ è½½æƒé‡
        vae.load_state_dict(vae_state_dict)
        vae.eval()
        
        print(f"\nâœ… VAEæ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"  - æ¨¡å‹ç±»å‹: {type(vae).__name__}")
        print(f"  - Embedç»´åº¦: {vae.embed_dim}")
        print(f"  - è®­ç»ƒæ¨¡å¼: {vae.training}")
        
        # ==================== ç¤ºä¾‹3: æµ‹è¯•å‰å‘ä¼ æ’­ ====================
        print("\n" + "=" * 80)
        print("ğŸ§ª ç¤ºä¾‹3: æµ‹è¯•å‰å‘ä¼ æ’­")
        print("=" * 80)
        
        # åˆ›å»ºéšæœºè¾“å…¥
        batch_size = 1
        resolution = 64
        batch = {
            'dense_index': torch.rand(batch_size, 1, resolution, resolution, resolution)
        }
        
        print(f"\nğŸ“¥ è¾“å…¥:")
        print(f"  - å½¢çŠ¶: {batch['dense_index'].shape}")
        print(f"  - æ•°æ®ç±»å‹: {batch['dense_index'].dtype}")
        print(f"  - å€¼èŒƒå›´: [{batch['dense_index'].min():.3f}, {batch['dense_index'].max():.3f}]")
        
        with torch.no_grad():
            # ç¼–ç 
            z, posterior = vae.encode(batch, sample_posterior=True)
            
            print(f"\nğŸ“¤ ç¼–ç ç»“æœ:")
            print(f"  - æ½œåœ¨è¡¨ç¤ºå½¢çŠ¶: {z.shape}")
            print(f"  - å‡å€¼å½¢çŠ¶: {posterior.mean.shape}")
            print(f"  - æ ‡å‡†å·®å½¢çŠ¶: {posterior.std.shape}")
            
            # è§£ç 
            reconst = vae.decoder(z)
            
            print(f"\nğŸ”„ è§£ç ç»“æœ:")
            print(f"  - é‡å»ºå½¢çŠ¶: {reconst.shape}")
            print(f"  - ä¸è¾“å…¥å½¢çŠ¶ä¸€è‡´: {reconst.shape == batch['dense_index'].shape}")
            
        print("\nâœ… å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ!")
        
    except ImportError as e:
        print(f"\nâŒ å¯¼å…¥é”™è¯¯: {e}")
        print("\nè¯·ç¡®ä¿å·²å®‰è£…direct3d_s2åŒ…:")
        print("  pip install -e .")
        return
    
    # ==================== ç¤ºä¾‹4: ç®€å•ä½¿ç”¨å»ºè®® ====================
    print("\n" + "=" * 80)
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®")
    print("=" * 80)
    
    print("""
1. ç”¨äºç‰¹å¾æå–:
   z, _ = vae.encode(batch, sample_posterior=False)  # ä½¿ç”¨modeè€Œä¸æ˜¯sample
   
2. ç”¨äºç”Ÿæˆ:
   reconst = vae.decoder(z)
   
3. ç”¨äºå¾®è°ƒè®­ç»ƒ:
   vae.train()
   optimizer = torch.optim.Adam(vae.parameters(), lr=1e-4)
   
4. GPUåŠ é€Ÿ:
   vae = vae.to('cuda')
   batch = {k: v.to('cuda') for k, v in batch.items()}

5. æŸ¥çœ‹æ›´å¤šç¤ºä¾‹:
   python use_extracted_vae.py --help
    """)
    
    # ==================== æ£€æŸ¥å…¶ä»–VAE ====================
    print("\n" + "=" * 80)
    print("ğŸ“ æ£€æŸ¥å…¶ä»–VAEæ–‡ä»¶")
    print("=" * 80)
    
    other_vaes = [
        ("sparse_vae_512.pth", "Sparse VAE 512"),
        ("sparse_vae_1024.pth", "Sparse VAE 1024"),
    ]
    
    for filename, name in other_vaes:
        filepath = os.path.join(vae_dir, filename)
        if os.path.exists(filepath):
            size_mb = os.path.getsize(filepath) / (1024 * 1024)
            print(f"  âœ… {name}: {filename} ({size_mb:.1f} MB)")
        else:
            print(f"  âš ï¸  {name}: {filename} (æœªæ‰¾åˆ°)")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print("=" * 80)
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: VAE_EXTRACTION_README.md")
    print("  2. æ¯”è¾ƒVAEæ¶æ„: python use_extracted_vae.py --compare")
    print("  3. æµ‹è¯•å…¶ä»–VAE: python use_extracted_vae.py --vae-path vae_weights/sparse_vae_1024.pth --vae-type sparse_1024 --test")
    print()


if __name__ == '__main__':
    quick_demo()

