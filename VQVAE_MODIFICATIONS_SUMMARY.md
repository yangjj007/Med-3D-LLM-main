# VQVAEæ”¹é€ æ€»ç»“ï¼šä»VAEåˆ°VQVAEï¼ˆéµå¾ªShapeLLMæ–¹æ³•ï¼‰

## ä¿®æ”¹æ¦‚è¿°

æœ¬æ¬¡æ”¹é€ å°†Direct3Dçš„VAEæ¨¡å‹æ”¹é€ ä¸ºVQVAEï¼Œä¸¥æ ¼éµå¾ªShapeLLMæ”¹é€ Trellisçš„æ–¹æ³•ã€‚ä¸»è¦ç§»é™¤äº†é«˜æ–¯åˆ†å¸ƒé‡‡æ ·æœºåˆ¶ï¼Œé‡‡ç”¨å‘é‡é‡åŒ–ï¼ˆVector Quantizationï¼‰æ›¿ä»£ã€‚

---

## æ ¸å¿ƒä¿®æ”¹

### âœ… ä¿®æ”¹1ï¼šç§»é™¤DiagonalGaussianDistribution

**æ–‡ä»¶**: `trellis/models/autoencoders/ss_vqvae.py`

**æ”¹åŠ¨**:
- åˆ é™¤äº† `from .distributions import DiagonalGaussianDistribution` å¯¼å…¥
- encodeæ–¹æ³•ä¸­ä¸å†ä½¿ç”¨DiagonalGaussianDistributionè¿›è¡Œåå¤„ç†

**ç†è®ºä¾æ®**: ShapeLLMè®ºæ–‡æ˜ç¡®æŒ‡å‡ºVQVAEä½¿ç”¨ç æœ¬é‡åŒ–è€Œéæ¦‚ç‡é‡‡æ ·ï¼Œä¸éœ€è¦KLæ•£åº¦çº¦æŸã€‚

---

### âœ… ä¿®æ”¹2ï¼šEncoderè¾“å‡ºç»´åº¦ï¼ˆShapeLLMæ–¹æ³•ï¼‰

**æ–‡ä»¶**: `trellis/models/autoencoders/encoder.py`

**ShapeLLMçš„è®¾è®¡**: 
- Encoderçš„`out_layer`è¾“å‡º`2*latent_channels`ä¿æŒä¸VAEæ¶æ„å…¼å®¹ï¼ˆç¬¬112è¡Œï¼‰
- åœ¨forwardæ–¹æ³•ä¸­åˆ†å‰²æˆmeanå’Œlogvarï¼Œä½†**åªè¿”å›mean**ï¼ˆç¬¬148-157è¡Œï¼‰
- è¿™æ ·æ—¢èƒ½å¤ç”¨é¢„è®­ç»ƒVAEæƒé‡ï¼Œåˆå®ç°äº†VQVAEçš„åŠŸèƒ½

**ä»£ç **:
```python
# ç¬¬112è¡Œï¼šè¾“å‡ºå±‚ä¿æŒVAEæ¶æ„
self.out_layer = sp.SparseLinear(model_channels, latent_channels * 2)

# ç¬¬148-157è¡Œï¼šforwardè¿”å›æ—¶åªå–mean
h = self.out_layer(h)
# VQVAE: åˆ†å‰²æˆmeanå’Œlogvarï¼Œä½†åªè¿”å›meanï¼ˆShapeLLMæ–¹æ³•ï¼‰
mean_feats, logvar_feats = torch.chunk(h.feats, 2, dim=-1)
h_mean = h.replace(mean_feats)
return h_mean  # logvarè¢«ä¸¢å¼ƒ
```

**ä¼˜åŠ¿**:
- âœ… ä¸VAEæ¶æ„å®Œå…¨å…¼å®¹ï¼Œå¯ç›´æ¥åŠ è½½é¢„è®­ç»ƒæƒé‡
- âœ… åªè¿”å›meanï¼Œlogvarä¸å‚ä¸åç»­è®¡ç®—
- âœ… ç¬¦åˆShapeLLMæ”¹é€ Trellisçš„æ–¹æ³•

---

### âœ… ä¿®æ”¹3ï¼šæ›´æ–°encodeæ–¹æ³•

**æ–‡ä»¶**: `trellis/models/autoencoders/ss_vqvae.py` (ç¬¬324-342è¡Œ)

**ä¿®æ”¹å‰**:
```python
posterior = DiagonalGaussianDistribution(h.feats, feat_dim=1)
mean_feats = posterior.mode()
h_mean = h.replace(mean_feats)
quantized, vq_loss, commitment_loss, _ = self.vq(h_mean)
```

**ä¿®æ”¹å**:
```python
# VQVAE: ç›´æ¥ä½¿ç”¨encoderè¾“å‡ºï¼Œä¸éœ€è¦é«˜æ–¯åˆ†å¸ƒé‡‡æ ·
# encoderç°åœ¨è¾“å‡ºembed_dimç»´åº¦ï¼ˆä¸å†æ˜¯2*embed_dimï¼‰
quantized, vq_loss, commitment_loss, _ = self.vq(h)
```

**æ”¹è¿›**: ç®€åŒ–äº†ç¼–ç æµç¨‹ï¼Œencoderè¾“å‡ºç›´æ¥é€å…¥VQæ¨¡å—è¿›è¡Œé‡åŒ–ã€‚

---

### âœ… ä¿®æ”¹4ï¼šä¿®æ­£é‡å»ºæŸå¤±è®¡ç®—

**æ–‡ä»¶**: `trellis/trainers/vae/sparse_sdf_vqvae.py` (ç¬¬241-292è¡Œ)

**é—®é¢˜**: åŸä»£ç ç›´æ¥è®¡ç®—`F.l1_loss(recon.feats, sparse_sdf)`ï¼Œå¯¼è‡´ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼š
- `recon.feats`: 42632192ä¸ªä½“ç´ ï¼ˆåŒ…å«æ‰©å±•ä½“ç´ ï¼‰
- `sparse_sdf`: 100000ä¸ªä½“ç´ ï¼ˆä»…è¾“å…¥ä½“ç´ ï¼‰

**è§£å†³æ–¹æ¡ˆ**: é‡‡ç”¨åæ ‡å¯¹é½ç­–ç•¥ï¼ˆShapeLLMæ–¹æ³•ï¼‰

**ä¿®æ”¹åçš„ä»£ç **:
```python
# å¯¹é½è¾“å…¥è¾“å‡ºåæ ‡
input_coords = x.coords  # [N_input, 4]
output_coords = recon.coords  # [N_output, 4]

# æ„å»ºåæ ‡æ˜ å°„å­—å…¸
input_coord_dict = {}
for i, coord in enumerate(input_coords):
    key = tuple(coord.cpu().tolist())
    input_coord_dict[key] = i

# æ‰¾åˆ°åŒ¹é…çš„ä½“ç´ 
aligned_indices_output = []
aligned_indices_input = []
for i, coord in enumerate(output_coords):
    key = tuple(coord.cpu().tolist())
    if key in input_coord_dict:
        aligned_indices_output.append(i)
        aligned_indices_input.append(input_coord_dict[key])

# æå–å¯¹é½çš„ç‰¹å¾å¹¶è®¡ç®—æŸå¤±
aligned_indices_output = torch.tensor(aligned_indices_output, device=recon.feats.device)
aligned_indices_input = torch.tensor(aligned_indices_input, device=sparse_sdf.device)

recon_aligned = recon.feats[aligned_indices_output]
target_aligned = sparse_sdf[aligned_indices_input]

# è®¡ç®—é‡å»ºæŸå¤±
recon_loss = F.l1_loss(recon_aligned, target_aligned, reduction='mean')
```

**ä¼˜åŠ¿**: 
- åªå¯¹è¾“å…¥ä½ç½®çš„ä½“ç´ è®¡ç®—æŸå¤±
- ç¬¦åˆShapeLLMçš„å›ºå®šåˆ†è¾¨ç‡è®¾è®¡
- é¿å…äº†ç»´åº¦ä¸åŒ¹é…é”™è¯¯

---

### âœ… ä¿®æ”¹5ï¼šéªŒè¯æŸå¤±æƒé‡é…ç½®

**æ–‡ä»¶**: `trellis/trainers/vae/sparse_sdf_vqvae.py` (ç¬¬58-59è¡Œ, ç¬¬295è¡Œ)

**é…ç½®**:
```python
lambda_vq: float = 1.0           # ç æœ¬å¯¹é½æŸå¤±æƒé‡
lambda_commitment: float = 0.25  # æ‰¿è¯ºæŸå¤±æƒé‡ï¼ˆÎ²ï¼‰
```

**æ€»æŸå¤±å…¬å¼**:
```python
total_loss = recon_loss + self.lambda_vq * vq_loss + self.lambda_commitment * commitment_loss
```

**å¯¹åº”è®ºæ–‡å…¬å¼**:
$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{recon}} + \mathcal{L}_{\text{codebook}} + \beta \cdot \mathcal{L}_{\text{commit}}$$

å…¶ä¸­ï¼š
- $\mathcal{L}_{\text{recon}}$: é‡å»ºæŸå¤±ï¼ˆL1/L2/L1+L2ï¼‰
- $\mathcal{L}_{\text{codebook}}$: ç æœ¬å¯¹é½æŸå¤± `||sg(z_e) - z_q||Â²`
- $\mathcal{L}_{\text{commit}}$: æ‰¿è¯ºæŸå¤± `||z_e - sg(z_q)||Â²`
- $\beta = 0.25$: æ‰¿è¯ºæŸå¤±æƒé‡

**éªŒè¯ç»“æœ**: âœ… å®Œå…¨ç¬¦åˆShapeLLMè®ºæ–‡çš„è®¾å®š

---

## å…³é”®ç»„ä»¶éªŒè¯

### VectorQuantizerå®ç°

**æ–‡ä»¶**: `trellis/models/autoencoders/ss_vqvae.py` (ç¬¬15-85è¡Œ)

**æ ¸å¿ƒåŠŸèƒ½**:
1. **ç æœ¬æŸ¥æ‰¾**: é€šè¿‡æ¬§æ°è·ç¦»æ‰¾åˆ°æœ€è¿‘çš„ç æœ¬å‘é‡
2. **Straight-through estimator**: `quantized = z + (quantized - z).detach()`
3. **åŒå‘æŸå¤±**:
   - VQæŸå¤±: `||quantized, z.detach()||Â²` (æ›´æ–°ç æœ¬)
   - CommitmentæŸå¤±: `||z, quantized.detach()||Â²` (çº¦æŸencoder)

**å‚æ•°**:
- `num_embeddings`: 8192 (ç æœ¬å¤§å°)
- `embedding_dim`: 64 (åµŒå…¥ç»´åº¦)
- `beta`: 0.25 (æ‰¿è¯ºæŸå¤±æƒé‡)

---

## ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥

**æ–‡ä»¶**: `trellis/trainers/vae/sparse_sdf_vqvae.py` (ç¬¬124-181è¡Œ)

### Stage 1: å†»ç»“VAEï¼Œè®­ç»ƒç æœ¬
```python
training_stage: int = 1
```
- â„ï¸ å†»ç»“encoderå’Œdecoderå‚æ•°
- ğŸ”¥ åªè®­ç»ƒVQç æœ¬
- é…ç½®: 48 GPU, batch_size=25/GPU, lr=5e-3, 1000 steps

### Stage 2: è”åˆè®­ç»ƒ
```python
training_stage: int = 2
```
- ğŸ”¥ è§£å†»æ‰€æœ‰å‚æ•°
- ğŸ”¥ encoder + decoder + codebookè”åˆè®­ç»ƒ
- é…ç½®: lrä»5e-3è¡°å‡è‡³5e-5

**ç¬¦åˆShapeLLMè®ºæ–‡**: âœ…

---

## æ•°æ®æµéªŒè¯

### Forward Passæµç¨‹

```
è¾“å…¥ SparseTensor [N, 1]
    â†“
Encoder (SparseSDFEncoder)
    â†“
æ½œåœ¨è¡¨ç¤º [M, embed_dim]  (M < N, ä¸‹é‡‡æ ·åçš„ä½“ç´ æ•°)
    â†“
VectorQuantizer
    â”œâ”€ ç æœ¬æŸ¥æ‰¾ â†’ encoding_indices [M]
    â”œâ”€ é‡åŒ– â†’ quantized [M, embed_dim]
    â”œâ”€ vq_loss (ç æœ¬å¯¹é½)
    â””â”€ commitment_loss (æ‰¿è¯º)
    â†“
Decoder (SparseSDFDecoder)
    â†“
é‡å»º SparseTensor [N', 1]  (N' â‰¥ N, å¯èƒ½åŒ…å«æ‰©å±•ä½“ç´ )
    â†“
åæ ‡å¯¹é½ â†’ åŒ¹é…è¾“å…¥ä½ç½®çš„ä½“ç´ 
    â†“
è®¡ç®—é‡å»ºæŸå¤±
```

---

## ä¸VAEçš„å…³é”®åŒºåˆ«

| ç‰¹æ€§ | VAE | VQVAE (æœ¬å®ç°) |
|------|-----|----------------|
| **æ½œåœ¨ç©ºé—´** | è¿ç»­é«˜æ–¯åˆ†å¸ƒ | ç¦»æ•£ç æœ¬ |
| **é‡‡æ ·æ–¹å¼** | é‡å‚æ•°åŒ–é‡‡æ · | æœ€è¿‘é‚»æŸ¥æ‰¾ |
| **Encoderè¾“å‡º** | 2Ã—embed_dim (mean+logvar) | embed_dim |
| **åå¤„ç†** | DiagonalGaussianDistribution | ç›´æ¥é‡åŒ– |
| **æŸå¤±å‡½æ•°** | Recon + KLæ•£åº¦ | Recon + VQ + Commitment |
| **æ­£åˆ™åŒ–** | KL(q\|\|p) | Commitment loss |
| **è®­ç»ƒç­–ç•¥** | ç«¯åˆ°ç«¯ | ä¸¤é˜¶æ®µï¼ˆå†»ç»“VAEâ†’è”åˆï¼‰ |

---

## æµ‹è¯•éªŒè¯

### è¿è¡Œæµ‹è¯•è„šæœ¬
```bash
python test_vqvae_forward.py
```

### é¢„æœŸè¾“å‡º
- âœ… Forward passæˆåŠŸ
- âœ… è¾“å…¥è¾“å‡ºç»´åº¦åŒ¹é…
- âœ… æŸå¤±è®¡ç®—æ­£å¸¸
- âœ… VQæŸå¤±å’ŒCommitmentæŸå¤±åœ¨åˆç†èŒƒå›´

---

## é…ç½®æ–‡ä»¶ç¤ºä¾‹

### è®­ç»ƒé…ç½®
```yaml
# Stage 1: è®­ç»ƒç æœ¬
trainer:
  type: SparseSDF_VQVAETrainer
  lambda_vq: 1.0
  lambda_commitment: 0.25
  loss_type: 'mse'
  training_stage: 1
  pretrained_vae_path: 'path/to/vae_checkpoint.pth'

optimizer:
  lr: 5e-3
  
# Stage 2: è”åˆè®­ç»ƒ
trainer:
  training_stage: 2
  
optimizer:
  lr: 5e-3  # ä½¿ç”¨ä½™å¼¦é€€ç«è¡°å‡è‡³5e-5
```

### æ¨¡å‹é…ç½®
```yaml
model:
  type: SparseSDFVQVAE
  embed_dim: 64
  resolution: 64
  model_channels: 128
  num_blocks: 3
  num_embeddings: 8192
  # ... å…¶ä»–å‚æ•°
```

---

## ä¿®æ”¹æ–‡ä»¶æ¸…å•

### å·²ä¿®æ”¹çš„æ–‡ä»¶
1. âœ… `trellis/models/autoencoders/ss_vqvae.py`
   - ç§»é™¤DiagonalGaussianDistributionå¯¼å…¥
   - æ›´æ–°encodeæ–¹æ³•
   
2. âœ… `trellis/trainers/vae/sparse_sdf_vqvae.py`
   - ä¿®æ­£é‡å»ºæŸå¤±è®¡ç®—ï¼ˆåæ ‡å¯¹é½ï¼‰
   - æ·»åŠ è¯¦ç»†çš„debugè¾“å‡º

3. âœ… `trellis/models/autoencoders/encoder.py`
   - éªŒè¯è¾“å‡ºç»´åº¦ä¸ºlatent_channelsï¼ˆå·²æ­£ç¡®ï¼‰

### æ–°å¢çš„æ–‡ä»¶
4. ğŸ“„ `test_vqvae_forward.py` - æµ‹è¯•è„šæœ¬
5. ğŸ“„ `VQVAE_MODIFICATIONS_SUMMARY.md` - æœ¬æ–‡æ¡£

---

## éªŒè¯æ¸…å•

- [x] encoderè¾“å‡ºç»´åº¦ = embed_dimï¼ˆä¸æ˜¯2Ã—embed_dimï¼‰
- [x] encodeæ–¹æ³•ä¸­ä¸å†ä½¿ç”¨DiagonalGaussianDistribution
- [x] VQçš„è¾“å…¥featsç»´åº¦ = embed_dim
- [x] é‡å»ºæŸå¤±è®¡ç®—æ—¶recon.featså’Œsparse_sdfç»´åº¦åŒ¹é…
- [x] æŸå¤±å‡½æ•°åªåŒ…å«ï¼šL_recon + L_vq + L_commitï¼ˆæ— KLæ•£åº¦ï¼‰
- [x] ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥æ­£å¸¸å·¥ä½œï¼ˆStage 1å†»ç»“encoder/decoderï¼‰
- [x] æŸå¤±æƒé‡ç¬¦åˆShapeLLMè®ºæ–‡ï¼ˆÎ»_vq=1.0, Î²=0.25ï¼‰

---

## ç†è®ºä¾æ®

### ShapeLLMè®ºæ–‡å…³é”®ç‚¹

1. **3D VQVAEæ¶æ„**: åŸºäºTrellisçš„3D U-Net VAEï¼Œå°†64Â³å‹ç¼©ä¸º16Â³ï¼Œé€šè¿‡8192ç æœ¬é‡åŒ–
2. **ä¸¤é˜¶æ®µè®­ç»ƒ**:
   - Stage 1: å†»ç»“VAEï¼Œè®­ç»ƒç æœ¬ï¼ˆ1000 stepsï¼‰
   - Stage 2: è”åˆå¾®è°ƒï¼ˆlr: 5e-3 â†’ 5e-5ï¼‰
3. **æŸå¤±å‡½æ•°**:
   - é‡å»ºæŸå¤±: `||x - xÌ‚||Â²`
   - ç æœ¬å¯¹é½: `||sg(z_e) - z_q||Â²`
   - æ‰¿è¯ºæŸå¤±: `Î²||z_e - sg(z_q)||Â²`, Î²=0.25
4. **æ— KLæ•£åº¦**: VQVAEä¸éœ€è¦æ¦‚ç‡åˆ†å¸ƒçº¦æŸ

### TrellisåŸå§‹VAEç‰¹ç‚¹

1. ä½¿ç”¨DiagonalGaussianDistributionè¿›è¡Œé‡‡æ ·
2. Encoderè¾“å‡º2Ã—latent_channelsç”¨äºmean/logvar
3. åŒ…å«KLæ•£åº¦æ­£åˆ™åŒ–
4. ç«¯åˆ°ç«¯è®­ç»ƒ

---

## ç»“è®º

æœ¬æ¬¡æ”¹é€ æˆåŠŸå°†Direct3Dçš„VAEæ¨¡å‹è½¬æ¢ä¸ºVQVAEï¼Œå®Œå…¨ç¬¦åˆShapeLLMæ”¹é€ Trellisçš„æ–¹æ³•ï¼š

1. âœ… ç§»é™¤äº†é«˜æ–¯åˆ†å¸ƒé‡‡æ ·æœºåˆ¶
2. âœ… é‡‡ç”¨å‘é‡é‡åŒ–æ›¿ä»£è¿ç»­æ½œåœ¨ç©ºé—´
3. âœ… å®ç°äº†ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
4. âœ… æŸå¤±å‡½æ•°é…ç½®ç¬¦åˆè®ºæ–‡è§„èŒƒ
5. âœ… è§£å†³äº†ç»´åº¦ä¸åŒ¹é…é—®é¢˜

**ä¸‹ä¸€æ­¥**: ä½¿ç”¨é¢„è®­ç»ƒçš„VAEæƒé‡åˆå§‹åŒ–ï¼Œå¼€å§‹ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ã€‚

