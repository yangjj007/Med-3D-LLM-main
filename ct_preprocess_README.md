# CTæ•°æ®é¢„å¤„ç†æ¨¡å— - ä½¿ç”¨æ–‡æ¡£

## æ¦‚è¿°

æœ¬æ¨¡å—æä¾›3DåŒ»å­¦CTæ•°æ®çš„å®Œæ•´é¢„å¤„ç†æµç¨‹ï¼ŒåŒ…æ‹¬åˆ†è¾¨ç‡é€‚é…ã€çª—å®½/çª—ä½äºŒå€¼åŒ–ã€å™¨å®˜ç‰¹å®šçª—å£å¤„ç†å’Œè¯­ä¹‰åˆ†å‰²æ ‡ç­¾å¤„ç†ã€‚é¢„å¤„ç†åçš„æ•°æ®å¯ç”¨äºTRELLIS Sparse SDFæ¨¡å‹è®­ç»ƒæˆ–å…¶ä»–3DåŒ»å­¦å›¾åƒåˆ†æä»»åŠ¡ã€‚

### æ ¸å¿ƒåŠŸèƒ½

1. **åˆ†è¾¨ç‡é€‚é…**ï¼šå°†ä¸è§„åˆ™çš„3D CTæ•°ç»„é€‚é…åˆ°æ ‡å‡†åˆ†è¾¨ç‡ï¼ˆ512Â³æˆ–1024Â³ï¼‰
   - åªæ”¯æŒå‘ä¸Šå…¼å®¹ï¼Œä¸æ”¯æŒå‘ä¸‹å‹ç¼©
   - ä¸è¶³çš„ç»´åº¦ç”¨ç©ºæ°”HUå€¼ï¼ˆ-1000ï¼‰å¡«å……

2. **çª—å®½/çª—ä½äºŒå€¼åŒ–**ï¼šæ ¹æ®é¢„å®šä¹‰çš„çª—å£è®¾ç½®å¯¹CTè¿›è¡ŒäºŒå€¼åŒ–
   - è‚ºçª—ï¼šçª—å®½1500 HUï¼Œçª—ä½-600 HU
   - éª¨çª—ï¼šçª—å®½1500 HUï¼Œçª—ä½300 HU
   - è½¯ç»„ç»‡çª—ï¼šçª—å®½400 HUï¼Œçª—ä½50 HU
   - è„‘çª—ï¼šçª—å®½80 HUï¼Œçª—ä½35 HU

3. **å™¨å®˜ç‰¹å®šå¤„ç†**ï¼šç»“åˆåˆ†å‰²æ©ç ï¼Œæå–æ¯ä¸ªå™¨å®˜åœ¨å¯¹åº”çª—å£ä¸‹çš„æ•°æ®

4. **æ•°æ®ç®¡ç†**ï¼šç»Ÿä¸€çš„æ–‡ä»¶å‘½åè§„èŒƒå’Œç›®å½•ç»“æ„

## å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ä¾èµ–
pip install numpy scipy pandas tqdm

# NIfTIæ–‡ä»¶å¤„ç†ï¼ˆå¿…éœ€ï¼‰
pip install monai nibabel

# å¯é€‰ï¼šç”¨äºSparse SDFç”Ÿæˆï¼ˆéœ€è¦CUDAï¼‰
pip install torch trimesh

# ç¼–è¯‘voxelizeåº“ï¼ˆå¿…éœ€ï¼‰
pip install ./third_party/voxelize/
```

## å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®

ç³»ç»Ÿæ”¯æŒå¤šç§æ•°æ®æ ¼å¼å’Œç›®å½•ç»“æ„ï¼š

#### æ ¼å¼1ï¼šNIfTIæ ¼å¼ï¼ˆåŒ»å­¦å½±åƒæ ‡å‡†æ ¼å¼ï¼‰

```
your_data_root/
â”œâ”€â”€ imagesTr/
â”‚   â”œâ”€â”€ case_001_0000.nii.gz
â”‚   â”œâ”€â”€ case_002_0000.nii.gz
â”‚   â””â”€â”€ ...
â””â”€â”€ labelsTr/
    â”œâ”€â”€ case_001.nii.gz
    â”œâ”€â”€ case_002.nii.gz
    â””â”€â”€ ...
```

#### æ ¼å¼2ï¼šM3D-Segæ ¼å¼ï¼ˆNPYæ•°ç»„æ ¼å¼ï¼‰

```
dataset_0000/
â”œâ”€â”€ 0000.json          # æ•°æ®é›†é…ç½®å’Œæ ‡ç­¾ä¿¡æ¯
â”œâ”€â”€ 1/
â”‚   â”œâ”€â”€ image.npy      # CTå›¾åƒæ•°ç»„
â”‚   â””â”€â”€ mask_(1, 512, 512, 96).npz  # åˆ†å‰²æ©ç ï¼ˆç¨€ç–æ ¼å¼ï¼‰
â”œâ”€â”€ 2/
â”‚   â”œâ”€â”€ image.npy
â”‚   â””â”€â”€ mask_*.npz
â””â”€â”€ ...
```

#### æ ¼å¼3ï¼šåŒ…å«å¤šä¸ªæ•°æ®é›†çš„å¤§æ–‡ä»¶å¤¹

```
all_datasets/
â”œâ”€â”€ dataset_A/          # NIfTIæ ¼å¼
â”‚   â”œâ”€â”€ imagesTr/
â”‚   â””â”€â”€ labelsTr/
â”œâ”€â”€ dataset_B/          # NIfTIæ ¼å¼
â”‚   â”œâ”€â”€ imagesTr/
â”‚   â””â”€â”€ labelsTr/
â”œâ”€â”€ m3d_0000/          # M3D-Segæ ¼å¼
â”‚   â”œâ”€â”€ 0000.json
â”‚   â”œâ”€â”€ 1/
â”‚   â””â”€â”€ 2/
â”œâ”€â”€ m3d_0001/          # M3D-Segæ ¼å¼
â”‚   â”œâ”€â”€ 0001.json
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

ç³»ç»Ÿä¼šè‡ªåŠ¨é€’å½’æ‰«æå¹¶è¯†åˆ«æ‰€æœ‰æ•°æ®é›†ï¼

### 2. åˆ›å»ºå™¨å®˜æ˜ å°„é…ç½®

åˆ›å»ºä¸€ä¸ªJSONæ–‡ä»¶ï¼ˆä¾‹å¦‚`organ_labels.json`ï¼‰ï¼š

```json
{
  "dataset_name": "MyDataset",
  "modality": "CT",
  "organ_labels": {
    "1": {"name": "liver", "window": "soft_tissue"},
    "2": {"name": "right_kidney", "window": "soft_tissue"},
    "3": {"name": "left_kidney", "window": "soft_tissue"},
    "4": {"name": "spleen", "window": "soft_tissue"}
  },
  "default_resolution": 512
}
```

å‚è€ƒç¤ºä¾‹ï¼š`dataset_toolkits/ct_preprocessing/organ_mapping_example.json`

### 3. è¿è¡Œé¢„å¤„ç†

#### æ–¹æ³•1ï¼šé€’å½’å¤„ç†å¤šä¸ªæ•°æ®é›†ï¼ˆæ¨èï¼‰

é€‚ç”¨äºåŒ…å«å¤šä¸ªæ•°æ®é›†çš„å¤§æ–‡ä»¶å¤¹ï¼Œè‡ªåŠ¨è¯†åˆ«æ ¼å¼ï¼š

```bash
bash scripts/prepare_ct_recursive.sh \
    ./med_dataset \
    ./processed_dataset \
    ./organ_labels.json \
    8 \
    5
```

å‚æ•°è¯´æ˜ï¼š
- ç¬¬1ä¸ªå‚æ•°ï¼šæ ¹ç›®å½•ï¼ˆåŒ…å«å¤šä¸ªæ•°æ®é›†ï¼‰
- ç¬¬2ä¸ªå‚æ•°ï¼šè¾“å‡ºåŸºç¡€ç›®å½•
- ç¬¬3ä¸ªå‚æ•°ï¼šå™¨å®˜æ ‡ç­¾æ˜ å°„JSONï¼ˆå¯é€‰ï¼Œç”¨äºNIfTIæ ¼å¼ï¼‰
- ç¬¬4ä¸ªå‚æ•°ï¼šå¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤4ï¼‰
- ç¬¬5ä¸ªå‚æ•°ï¼šæœ€å¤§é€’å½’æ·±åº¦ï¼ˆå¯é€‰ï¼Œé»˜è®¤5ï¼‰

ç‰¹ç‚¹ï¼š
- ğŸ” è‡ªåŠ¨é€’å½’æ‰«ææ‰€æœ‰å­æ–‡ä»¶å¤¹
- ğŸ“Š è‡ªåŠ¨è¯†åˆ«NIfTIå’ŒM3D-Segæ ¼å¼
- âš¡ å¹¶è¡Œå¤„ç†å¤šä¸ªæ•°æ®é›†
- ğŸ“‹ ç»Ÿä¸€è¾“å‡ºæ ¼å¼
- ğŸ“ ç”Ÿæˆæ€»ç»“æŠ¥å‘Š

#### æ–¹æ³•2ï¼šå¤„ç†å•ä¸ªNIfTIæ•°æ®é›†

```bash
bash scripts/prepare_medical_ct_dataset.sh \
    /path/to/nifti_data \
    ./data/processed_ct \
    ./organ_labels.json \
    8
```

#### æ–¹æ³•3ï¼šå¤„ç†å•ä¸ªM3D-Segæ•°æ®é›†

```bash
python dataset_toolkits/process_m3d_seg_format.py \
    --data_root /path/to/m3d_dataset \
    --output_dir ./data/processed_ct \
    --num_workers 8
```

### 4. é¢„è®¡ç®—SDF


### 5. è¾“å‡ºç»“æœ

å¤„ç†å®Œæˆåï¼Œè¾“å‡ºç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
processed_ct/
â”œâ”€â”€ metadata.csv                    # å…ƒæ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰æ ·æœ¬ä¿¡æ¯ï¼‰
â”œâ”€â”€ dataset_config.json             # æ•°æ®é›†å…¨å±€é…ç½®
â””â”€â”€ processed/
    â”œâ”€â”€ case_001/
    â”‚   â”œâ”€â”€ ct_original_512.npy    # åŸå§‹CTï¼ˆé€‚é…åˆ°512Â³ï¼‰
    â”‚   â”œâ”€â”€ ct_normalized_512.npy  # æ ‡å‡†åŒ–åçš„CT
    â”‚   â”œâ”€â”€ windows/               # å…¨å±€çª—å£äºŒå€¼åŒ–ç»“æœ
    â”‚   â”‚   â”œâ”€â”€ lung_w1500_l-600.npy
    â”‚   â”‚   â”œâ”€â”€ bone_w1500_l300.npy
    â”‚   â”‚   â”œâ”€â”€ soft_tissue_w400_l50.npy
    â”‚   â”‚   â””â”€â”€ brain_w80_l35.npy
    â”‚   â”œâ”€â”€ organs/                # å™¨å®˜ç‰¹å®šçª—å£ç»“æœ
    â”‚   â”‚   â”œâ”€â”€ liver/
    â”‚   â”‚   â”‚   â””â”€â”€ soft_tissue_w400_l50.npy
    â”‚   â”‚   â”œâ”€â”€ lung/
    â”‚   â”‚   â”‚   â””â”€â”€ lung_w1500_l-600.npy
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ masks/                 # åŸå§‹åˆ†å‰²æ©ç 
    â”‚   â”‚   â””â”€â”€ segmentation_masks.npz
    â”‚   â””â”€â”€ info.json              # æ ·æœ¬å…ƒä¿¡æ¯
    â””â”€â”€ case_002/
        â””â”€â”€ ...
```

## æ•°æ®åŠ è½½ç¤ºä¾‹

### åŠ è½½é¢„å¤„ç†åçš„æ•°æ®

```python
import numpy as np
import pandas as pd
from scipy import sparse
import json
import os

# 1. åŠ è½½å…ƒæ•°æ®
metadata_path = './data/processed_ct/metadata.csv'
metadata = pd.read_csv(metadata_path)
print(f"æ€»ç—…ä¾‹æ•°: {len(metadata)}")

# 2. é€‰æ‹©ä¸€ä¸ªç—…ä¾‹
case_id = metadata.iloc[0]['case_id']
print(f"åŠ è½½ç—…ä¾‹: {case_id}")

# 3. åŠ è½½æ ‡å‡†åŒ–çš„CTæ•°æ®
ct_path = f'./data/processed_ct/processed/{case_id}/ct_normalized_512.npy'
ct_array = np.load(ct_path)
print(f"CTå½¢çŠ¶: {ct_array.shape}")

# 4. åŠ è½½çª—å£æ•°æ®
lung_window = np.load(f'./data/processed_ct/processed/{case_id}/windows/lung_w1500_l-600.npy')
bone_window = np.load(f'./data/processed_ct/processed/{case_id}/windows/bone_w1500_l300.npy')
print(f"è‚ºçª—å½¢çŠ¶: {lung_window.shape}")
print(f"éª¨çª—å½¢çŠ¶: {bone_window.shape}")

# 5. åŠ è½½åˆ†å‰²æ©ç 
mask_path = f'./data/processed_ct/processed/{case_id}/masks/segmentation_masks.npz'
seg_sparse = sparse.load_npz(mask_path)
seg_shape = (512, 512, 512)  # ä»info.jsonè·å–
seg_array = seg_sparse.toarray().reshape(seg_shape)
print(f"åˆ†å‰²å½¢çŠ¶: {seg_array.shape}")
print(f"å”¯ä¸€æ ‡ç­¾: {np.unique(seg_array)}")

# 6. åŠ è½½å™¨å®˜ç‰¹å®šæ•°æ®
liver_path = f'./data/processed_ct/processed/{case_id}/organs/liver/soft_tissue_w400_l50.npy'
if os.path.exists(liver_path):
    liver_window = np.load(liver_path)
    print(f"è‚è„çª—å£ä½“ç´ æ•°: {np.sum(liver_window)}")

# 7. åŠ è½½å…ƒä¿¡æ¯
info_path = f'./data/processed_ct/processed/{case_id}/info.json'
with open(info_path, 'r') as f:
    info = json.load(f)
print(f"åŸå§‹å½¢çŠ¶: {info['original_shape']}")
print(f"å¤„ç†æ—¶é—´: {info['processing_time_sec']}ç§’")
```

### æ‰¹é‡æ•°æ®åŠ è½½å™¨

```python
class CTDataLoader:
    """CTæ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, processed_dir, resolution=512):
        self.processed_dir = processed_dir
        self.resolution = resolution
        
        # åŠ è½½å…ƒæ•°æ®
        metadata_path = os.path.join(processed_dir, 'metadata.csv')
        self.metadata = pd.read_csv(metadata_path)
        
    def __len__(self):
        return len(self.metadata)
    
    def load_case(self, idx):
        """åŠ è½½å•ä¸ªç—…ä¾‹"""
        row = self.metadata.iloc[idx]
        case_id = row['case_id']
        
        case_dir = os.path.join(self.processed_dir, 'processed', case_id)
        
        # åŠ è½½CT
        ct_path = os.path.join(case_dir, f'ct_normalized_{self.resolution}.npy')
        ct = np.load(ct_path)
        
        # åŠ è½½åˆ†å‰²ï¼ˆå¦‚æœæœ‰ï¼‰
        seg = None
        if row.get('has_segmentation', False):
            mask_path = os.path.join(case_dir, 'masks', 'segmentation_masks.npz')
            if os.path.exists(mask_path):
                seg_sparse = sparse.load_npz(mask_path)
                seg_shape = tuple(map(int, row['adapted_shape'].split(',')))
                seg = seg_sparse.toarray().reshape(seg_shape)
        
        return {
            'case_id': case_id,
            'ct': ct,
            'segmentation': seg,
            'info': row.to_dict()
        }
    
    def load_window(self, case_id, window_name):
        """åŠ è½½ç‰¹å®šçª—å£"""
        window_path = os.path.join(
            self.processed_dir, 'processed', case_id, 
            'windows', f'{window_name}.npy'
        )
        return np.load(window_path)

# ä½¿ç”¨ç¤ºä¾‹
loader = CTDataLoader('./data/processed_ct')
print(f"æ•°æ®é›†å¤§å°: {len(loader)}")

# åŠ è½½ç¬¬ä¸€ä¸ªç—…ä¾‹
data = loader.load_case(0)
print(f"ç—…ä¾‹ID: {data['case_id']}")
print(f"CTå½¢çŠ¶: {data['ct'].shape}")
```

### ç”¨äºè®­ç»ƒçš„æ•°æ®è¿­ä»£å™¨

```python
import torch
from torch.utils.data import Dataset, DataLoader

class CTDataset(Dataset):
    """PyTorch Dataset for CT data"""
    
    def __init__(self, processed_dir, resolution=512, load_windows=True):
        self.processed_dir = processed_dir
        self.resolution = resolution
        self.load_windows = load_windows
        
        # åŠ è½½å…ƒæ•°æ®
        metadata_path = os.path.join(processed_dir, 'metadata.csv')
        self.metadata = pd.read_csv(metadata_path)
        
    def __len__(self):
        return len(self.metadata)
    
    def __getitem__(self, idx):
        row = self.metadata.iloc[idx]
        case_id = row['case_id']
        case_dir = os.path.join(self.processed_dir, 'processed', case_id)
        
        # åŠ è½½CT
        ct_path = os.path.join(case_dir, f'ct_normalized_{self.resolution}.npy')
        ct = np.load(ct_path)
        ct_tensor = torch.from_numpy(ct).float()
        
        # æ·»åŠ é€šé“ç»´åº¦ (1, H, W, D)
        if ct_tensor.dim() == 3:
            ct_tensor = ct_tensor.unsqueeze(0)
        
        data = {'ct': ct_tensor, 'case_id': case_id}
        
        # å¯é€‰ï¼šåŠ è½½çª—å£
        if self.load_windows:
            windows_dir = os.path.join(case_dir, 'windows')
            if os.path.exists(windows_dir):
                lung_window = np.load(os.path.join(windows_dir, 'lung_w1500_l-600.npy'))
                data['lung_window'] = torch.from_numpy(lung_window).float()
        
        return data

# ä½¿ç”¨ç¤ºä¾‹
dataset = CTDataset('./data/processed_ct')
dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4)

for batch in dataloader:
    print(f"Batch CT shape: {batch['ct'].shape}")
    print(f"Case IDs: {batch['case_id']}")
    break
```

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰çª—å£è®¾ç½®

```python
from dataset_toolkits.ct_preprocessing import add_custom_window

# æ·»åŠ è‡ªå®šä¹‰çª—å£
add_custom_window(
    window_name='custom_liver',
    window_width=350,
    window_level=60,
    organ_types=['liver'],
    description='è‚è„ä¸“ç”¨çª—å£'
)
```

### å•ä¸ªæ–‡ä»¶å¤„ç†ï¼ˆä¸ä½¿ç”¨ä¸»è„šæœ¬ï¼‰

```python
from dataset_toolkits.ct_preprocessing import (
    adapt_resolution,
    process_all_windows,
    normalize_ct
)
import numpy as np

# åŠ è½½ä½ çš„CTæ•°æ®ï¼ˆå‡è®¾å·²åŠ è½½ä¸ºnumpyæ•°ç»„ï¼‰
ct_array = np.load('your_ct.npy')
print(f"åŸå§‹å½¢çŠ¶: {ct_array.shape}")

# 1. åˆ†è¾¨ç‡é€‚é…
ct_adapted = adapt_resolution(ct_array, target_resolution=512)
print(f"é€‚é…åå½¢çŠ¶: {ct_adapted.shape}")

# 2. æ ‡å‡†åŒ–
ct_normalized = normalize_ct(ct_adapted, method='foreground')

# 3. çª—å£å¤„ç†
windows = process_all_windows(ct_normalized, binarize=True)
for window_name, binary_array in windows.items():
    print(f"{window_name}: {np.sum(binary_array)} æ­£å€¼ä½“ç´ ")

# 4. ä¿å­˜ç»“æœ
np.save('ct_normalized_512.npy', ct_normalized)
np.save('lung_window.npy', windows['lung'])
```

## å‚æ•°è¯´æ˜

### process_medical_ct.py å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--data_root` | str | å¿…éœ€ | NIfTIæ•°æ®æ ¹ç›®å½• |
| `--output_dir` | str | å¿…éœ€ | è¾“å‡ºç›®å½• |
| `--organ_labels` | str | None | å™¨å®˜æ ‡ç­¾æ˜ å°„JSONæ–‡ä»¶ |
| `--default_resolution` | int | 512 | é»˜è®¤ç›®æ ‡åˆ†è¾¨ç‡ï¼ˆ512æˆ–1024ï¼‰ |
| `--num_workers` | int | 4 | å¹¶è¡Œè¿›ç¨‹æ•° |
| `--max_cases` | int | None | æœ€å¤§å¤„ç†ç—…ä¾‹æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰ |

### åˆ†è¾¨ç‡é€‚é…è§„åˆ™

| è¾“å…¥æœ€å¤§ç»´åº¦ | ç›®æ ‡åˆ†è¾¨ç‡ | ç¤ºä¾‹ |
|------------|----------|------|
| â‰¤ 512 | 512Â³ | (512,512,100) â†’ (512,512,512) |
| 512 < d â‰¤ 1024 | 1024Â³ | (600,600,200) â†’ (1024,1024,1024) |
| > 1024 | é”™è¯¯ | ä¸æ”¯æŒ |

### çª—å£é…ç½®

| çª—å£åç§° | çª—å®½(HU) | çª—ä½(HU) | HUèŒƒå›´ | é€‚ç”¨å™¨å®˜ |
|---------|---------|---------|--------|---------|
| lung | 1500 | -600 | [-1350, 150] | è‚ºã€æ”¯æ°”ç®¡ |
| bone | 1500 | 300 | [-450, 1050] | éª¨éª¼ã€æ¤éª¨ |
| soft_tissue | 400 | 50 | [-150, 250] | è‚ã€è‚¾ã€è„¾ |
| brain | 80 | 35 | [-5, 75] | è„‘ç»„ç»‡ |

## æ–‡ä»¶å‘½åè§„èŒƒ

### CTæ–‡ä»¶
- åŸå§‹é€‚é…CTï¼š`ct_original_{resolution}.npy`
- æ ‡å‡†åŒ–CTï¼š`ct_normalized_{resolution}.npy`

### çª—å£æ–‡ä»¶
- æ ¼å¼ï¼š`{window_name}_w{width}_l{level}.npy`
- ç¤ºä¾‹ï¼š`lung_w1500_l-600.npy`ã€`bone_w1500_l300.npy`

### å™¨å®˜æ–‡ä»¶
- è·¯å¾„ï¼š`organs/{organ_name}/{window_name}_w{width}_l{level}.npy`
- ç¤ºä¾‹ï¼š`organs/liver/soft_tissue_w400_l50.npy`

### æ©ç æ–‡ä»¶
- ç¨€ç–æ ¼å¼ï¼š`masks/segmentation_masks.npz`

## æµ‹è¯•

è¿è¡Œå•å…ƒæµ‹è¯•éªŒè¯æ‰€æœ‰æ¨¡å—ï¼š

```bash
python tests/test_ct_preprocessing.py
```

æµ‹è¯•å†…å®¹åŒ…æ‹¬ï¼š
- é…ç½®æ¨¡å—
- åˆ†è¾¨ç‡é€‚é…å™¨
- çª—å£å¤„ç†å™¨
- å™¨å®˜æå–å™¨
- é›†æˆæµ‹è¯•
- æ–‡ä»¶æ“ä½œ

## æ€§èƒ½ä¼˜åŒ–

### å¹¶è¡Œå¤„ç†

ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿå¤„ç†ï¼š

```bash
# ä½¿ç”¨8ä¸ªè¿›ç¨‹
python dataset_toolkits/process_medical_ct.py \
    --data_root /path/to/data \
    --output_dir ./output \
    --num_workers 8
```

### å†…å­˜ä¼˜åŒ–

- ä½¿ç”¨uint8å­˜å‚¨äºŒå€¼åŒ–æ•°ç»„ï¼ˆèŠ‚çœ75%ç©ºé—´ï¼‰
- ä½¿ç”¨ç¨€ç–çŸ©é˜µå­˜å‚¨åˆ†å‰²æ©ç 
- ä½¿ç”¨np.savez_compressedå‹ç¼©å­˜å‚¨

### å­˜å‚¨ç©ºé—´ä¼°ç®—

ä»¥512Â³åˆ†è¾¨ç‡ä¸ºä¾‹ï¼Œå•ä¸ªç—…ä¾‹çº¦å ï¼š
- åŸå§‹CTï¼ˆfloat32ï¼‰ï¼š512 MB
- æ ‡å‡†åŒ–CTï¼ˆfloat32ï¼‰ï¼š512 MB
- å…¨å±€çª—å£ï¼ˆ4ä¸ªï¼Œuint8ï¼‰ï¼š512 MB
- å™¨å®˜çª—å£ï¼šå–å†³äºå™¨å®˜æ•°é‡
- æ€»è®¡ï¼šçº¦1.5-2 GB/ç—…ä¾‹

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•å¤„ç†æ²¡æœ‰åˆ†å‰²æ ‡ç­¾çš„æ•°æ®ï¼Ÿ

A: è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹ã€‚å¦‚æœæ²¡æœ‰æ ‡ç­¾æ–‡ä»¶ï¼Œå°†åªå¤„ç†CTæ•°æ®å’Œå…¨å±€çª—å£ï¼Œè·³è¿‡å™¨å®˜ç‰¹å®šå¤„ç†ã€‚

```bash
# æ— æ ‡ç­¾æ•°æ®ä¹Ÿå¯ä»¥æ­£å¸¸å¤„ç†
python dataset_toolkits/process_medical_ct.py \
    --data_root /path/to/data \
    --output_dir ./output
    # ä¸éœ€è¦æŒ‡å®š--organ_labels
```

### Q2: å¦‚ä½•ä¿®æ”¹çª—å®½/çª—ä½è®¾ç½®ï¼Ÿ

A: æœ‰ä¸¤ç§æ–¹æ³•ï¼š

1. ä¿®æ”¹é…ç½®æ–‡ä»¶ `dataset_toolkits/ct_preprocessing/config.py`
2. åœ¨ä»£ç ä¸­åŠ¨æ€æ·»åŠ ï¼š

```python
from dataset_toolkits.ct_preprocessing import add_custom_window

add_custom_window(
    window_name='my_window',
    window_width=500,
    window_level=100
)
```

### Q3: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

A: 
1. å‡å°‘å¹¶è¡Œè¿›ç¨‹æ•°ï¼š`--num_workers 1`
2. åˆ†æ‰¹å¤„ç†ï¼š`--max_cases 10`
3. ä½¿ç”¨æ›´å°çš„åˆ†è¾¨ç‡ï¼ˆä¿®æ”¹DEFAULT_RESOLUTIONï¼‰

### Q4: å¤„ç†é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

A:
1. å¢åŠ å¹¶è¡Œè¿›ç¨‹æ•°ï¼š`--num_workers 16`
2. ä½¿ç”¨SSDå­˜å‚¨
3. å…³é—­ä¸éœ€è¦çš„çª—å£å¤„ç†
4. ä¸ä¿å­˜ä¸­é—´ç»“æœï¼ˆä¿®æ”¹save_intermediateå‚æ•°ï¼‰

### Q5: å¦‚ä½•ä¸ºä¸åŒå™¨å®˜ä½¿ç”¨ä¸åŒçª—å£ï¼Ÿ

A: åœ¨å™¨å®˜æ ‡ç­¾æ˜ å°„JSONä¸­æŒ‡å®šï¼š

```json
{
  "organ_labels": {
    "1": {"name": "lung", "window": "lung"},
    "2": {"name": "liver", "window": "soft_tissue"},
    "3": {"name": "bone", "window": "bone"}
  }
}
```

### Q6: å¦‚ä½•éªŒè¯å¤„ç†ç»“æœæ˜¯å¦æ­£ç¡®ï¼Ÿ

A: ä½¿ç”¨å¯è§†åŒ–å·¥å…·æ£€æŸ¥ï¼š

```python
import matplotlib.pyplot as plt
import numpy as np

# åŠ è½½æ•°æ®
ct = np.load('processed_ct/processed/case_001/ct_normalized_512.npy')
lung_window = np.load('processed_ct/processed/case_001/windows/lung_w1500_l-600.npy')

# å¯è§†åŒ–ä¸­é—´åˆ‡ç‰‡
fig, axes = plt.subplots(1, 2, figsize=(12, 6))
axes[0].imshow(ct[:, :, 256], cmap='gray')
axes[0].set_title('åŸå§‹CT')
axes[1].imshow(lung_window[:, :, 256], cmap='gray')
axes[1].set_title('è‚ºçª—')
plt.show()
```

## ä¸TRELLISé›†æˆ

é¢„å¤„ç†åçš„æ•°æ®å¯ä»¥ç›´æ¥ç”¨äºTRELLISè®­ç»ƒï¼š

```bash
# 1. é¢„å¤„ç†CTæ•°æ®
bash scripts/prepare_medical_ct_dataset.sh \
    /path/to/nifti_data \
    ./data/processed_ct

# 2. ç”ŸæˆSparse SDFï¼ˆéœ€è¦CUDAï¼‰
python dataset_toolkits/compute_sparse_sdf.py \
    --output_dir ./data/processed_ct \
    --resolutions 512 \
    --input_type voxel \
    --max_workers 8

# 3. è®­ç»ƒTRELLIS
python train.py \
    --config configs/vae/sparse_sdf_vqvae_512.json \
    --output_dir ./outputs/ct_vqvae \
    --data_dir ./data/processed_ct
```

## æ•°æ®è¯»å–APIå‚è€ƒ

å®Œæ•´çš„æ•°æ®åŠ è½½APIåœ¨ `dataset_toolkits/datasets/MedicalCT.py` ä¸­ï¼š

```python
from dataset_toolkits.datasets.MedicalCT import get_data_loader

# è·å–æ•°æ®åŠ è½½å™¨
metadata = pd.read_csv('processed_ct/metadata.csv')
loader = get_data_loader(metadata, 'processed_ct', resolution=512)

# åŠ è½½æ•°æ®
sha256 = metadata.iloc[0]['sha256']
data = loader(sha256)

print(data.keys())  # ['ct', 'case_id', 'segmentation', 'windows']
```

## è´¡çŒ®ä¸æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£æˆ–æäº¤Issueã€‚

## è®¸å¯è¯

æœ¬æ¨¡å—éµå¾ªé¡¹ç›®æ•´ä½“è®¸å¯è¯ã€‚

