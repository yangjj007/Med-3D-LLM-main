# 数据集处理说明

## 概述

这个脚本用于将3D医学数据集（NIfTI格式）转换为M3D_Seg统一格式。

## 数据集信息

- **数据格式**: NIfTI (.nii.gz)
- **模态**: CT
- **类别**: 肝脏、右肾、左肾、脾脏

## 使用方法

### 1. 安装依赖

```bash
pip install numpy scipy scikit-learn monai nibabel
```

### 2. 运行处理脚本

```bash
python process_3dircad.py
```

### 3. 输出结果

处理完成后，会在当前目录生成 `0009` 文件夹，结构如下：

```
0009/
├── 1/
│   ├── image.npy
│   └── mask_(4, 512, 512, 129).npz
├── 2/
│   ├── image.npy
│   └── mask_(4, 512, 512, 172).npz
├── ...
└── 0009.json
```

### 4. 数据加载示例

使用 `data_load_demo.py` 加载处理后的数据：

```python
import numpy as np
from scipy import sparse
import ast
import os
import json

# 设置路径
dataset_code = '0009'
json_path = os.path.join('./', dataset_code, dataset_code + '.json')

# 读取数据集划分信息
with open(json_path, 'r') as f:
    dataset_dict = json.load(f)

# 加载第一个训练样本
ct_file_path = dataset_dict['train'][0]['image']
gt_file_path = dataset_dict['train'][0]['label']

# 读取图像
img_array = np.load(ct_file_path)
print('图像形状:', img_array.shape)

# 读取标签（稀疏矩阵格式）
allmatrix_sp = sparse.load_npz(gt_file_path)
gt_shape = ast.literal_eval(gt_file_path.split('.')[-2].split('_')[-1])
gt_array = allmatrix_sp.toarray().reshape(gt_shape)
print('标签形状:', gt_array.shape)

# 查看标签信息
print('\n标签类别:')
for label_id, label_name in dataset_dict['labels'].items():
    print(f'  {label_id}: {label_name}')
```

## 处理流程

1. **读取原始数据**: 从 `3Dircad/imagesTr` 和 `3Dircad/labelsTr` 读取 .nii.gz 文件
2. **图像标准化**: 对CT图像进行归一化处理
3. **标签转换**: 将多类别标签转换为多通道二值mask
4. **稀疏存储**: 使用稀疏矩阵格式保存标签，节省空间
5. **生成JSON**: 自动划分训练集和测试集（默认比例 8:2）

## 自定义配置

如果需要修改配置，可以编辑 `process_3dircad.py` 中的参数：

```python
# 类别标签
CATEGORY = [
    'liver',
    'right kidney',
    'left kidney',
    'spleen'
]

# 路径配置
IMAGE_DIR = './3Dircad/imagesTr'
LABEL_DIR = './3Dircad/labelsTr'
DATASET_CODE = '0009'
SAVE_ROOT = './'
TEST_RATIO = 0.2  # 测试集比例
```

## 处理其他数据集

如果你有其他NIfTI格式的数据集，只需要修改：

1. `IMAGE_DIR` 和 `LABEL_DIR`：指向你的数据集路径
2. `CATEGORY`：定义你的数据集包含的类别
3. `DATASET_CODE`：为你的数据集分配一个编号（如0025、0026等）
4. 文件名匹配逻辑：根据你的数据集文件命名规则调整代码

## 注意事项

1. **内存要求**: 3D医学图像较大，建议至少16GB内存
2. **处理时间**: 根据数据集大小，可能需要几分钟到几小时
3. **磁盘空间**: 处理后的数据大小约为原始数据的1-2倍
4. **多进程**: 默认使用4个进程，可根据CPU核心数调整

## 常见问题

### Q: 如何修改训练集/测试集比例？
A: 修改 `TEST_RATIO` 参数，例如 `TEST_RATIO = 0.3` 表示30%测试集

### Q: 如何处理包含更多类别的数据集？
A: 修改 `CATEGORY` 列表，添加所有类别名称

### Q: 如何查看处理进度？
A: 脚本会实时输出处理日志，显示当前处理的样本编号和状态

### Q: 处理失败怎么办？
A: 检查：
   - 是否安装了所有依赖包
   - 原始数据路径是否正确
   - 是否有足够的磁盘空间和内存
   - 查看错误信息进行针对性修复

